{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weight_normalize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcmin1018/CV/blob/main/notebooks/EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5J_ii5ytYlu",
        "outputId": "d5477c5a-0d0b-4086-a339-341fd26713a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os, sys \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc8HFTRqy_1l",
        "outputId": "4c58b53a-35c3-4933-80a4-bc966844f6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/drive/MyDrive/Colab Notebooks/data/test.zip\""
      ],
      "metadata": {
        "id": "BYAI_CTJzUyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/drive/MyDrive/Colab Notebooks/data/train.zip\""
      ],
      "metadata": {
        "id": "4cohbBN-zvg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import timm\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "import time\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3MsJoUAz7Rp",
        "outputId": "b5d41b58-0be9-4c35-b551-106e7875e2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIR = '/content/drive/MyDrive/Colab Notebooks/data/'\n",
        "TRAIN_SOURCE = os.path.join(DIR, \"train_df.csv\")\n",
        "TEST_SOURCE = os.path.join(DIR, \"test_df.csv\")\n",
        "SAMPLE_SUBMISSION = os.path.join(DIR, \"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "KI3nwfpTz8ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/train_df.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/test_df.csv')"
      ],
      "metadata": {
        "id": "nKf4qEf8z8H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_png = sorted(glob('/content/drive/MyDrive/Colab Notebooks/data/train/*.png'))\n",
        "test_png = sorted(glob('/content/drive/MyDrive/Colab Notebooks/data/test/*.png'))"
      ],
      "metadata": {
        "id": "5SV8Z1nz0UoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_df[\"label\"]\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
        "train_labels = [label_unique[k] for k in train_labels]"
      ],
      "metadata": {
        "id": "jFeejgLbCQQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = train_df['label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "gSsON891Dlk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_ratio = 10 - normalize *100"
      ],
      "metadata": {
        "id": "gPpjSSNRFqUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_list_all = np.ones(88)\n",
        "for key in weight_ratio.index:\n",
        "  idx = label_unique[key]\n",
        "  weight = weight_ratio[key]\n",
        "  weight_list_all[idx] = weight\n",
        "weight_list_all_tensor = torch.FloatTensor(weight_list_all).cuda()\n",
        "print(weight_list_all_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv7RH1QjGhiM",
        "outputId": "d5688ce8-9eb2-491b-d20f-70a920cc8160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.7662, 9.7428, 9.7428, 5.1134, 9.8363, 9.8597, 9.8597, 9.8363, 9.8831,\n",
            "        4.7627, 9.8597, 9.8831, 9.8831, 9.7194, 9.7428, 4.8796, 9.7428, 9.7194,\n",
            "        9.7662, 9.7662, 9.7896, 3.4534, 9.7896, 9.7896, 9.7662, 9.8597, 9.8597,\n",
            "        9.8597, 3.8274, 9.8597, 9.8597, 9.7896, 9.7896, 0.8581, 9.7896, 9.7896,\n",
            "        9.7662, 9.7662, 9.7896, 9.7662, 4.2717, 9.7896, 9.6960, 9.7428, 9.7194,\n",
            "        4.8562, 9.7194, 9.6960, 9.7896, 9.7428, 9.6960, 9.7662, 3.7573, 9.8831,\n",
            "        9.7194, 2.5181, 9.7194, 9.7194, 9.6960, 9.7194, 9.7194, 9.7896, 9.7896,\n",
            "        4.6224, 9.8130, 9.7896, 9.8130, 9.6493, 8.5971, 9.8831, 9.8831, 9.8831,\n",
            "        5.0199, 9.8831, 9.9065, 9.8597, 4.2249, 9.8831, 9.8831, 9.7428, 9.7662,\n",
            "        9.8130, 9.7896, 9.8130, 4.3886, 9.7896, 9.7896, 9.8130],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1]\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    return img"
      ],
      "metadata": {
        "id": "_An3eY17CxvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]"
      ],
      "metadata": {
        "id": "YXb9zXYpBXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf8ad76-d717-4f3d-ece4-8d80a7b791eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [05:29<00:00, 13.00it/s]\n",
            "100%|██████████| 2154/2154 [14:34<00:00,  2.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs, valid_imgs, train_labels, valid_labels = train_test_split(train_imgs, train_labels, test_size = 0.2, shuffle=True, stratify=train_labels, random_state = 2022)"
      ],
      "metadata": {
        "id": "qHSPw7cGo708"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_dataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode=='train':\n",
        "            augmentation = random.randint(0,2)\n",
        "            if augmentation==1:\n",
        "                img = img[::-1].copy()\n",
        "            elif augmentation==2:\n",
        "                img = img[:,::-1].copy()\n",
        "        img = transforms.ToTensor()(img)\n",
        "        if self.mode=='test':\n",
        "            pass\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "    \n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=88)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8F5bqA2YIYpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 24\n",
        "\n",
        "# Train\n",
        "train_dataset = Custom_dataset(train_imgs, train_labels, mode='train')\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# valid\n",
        "valid_dataset = Custom_dataset(train_imgs, train_labels, mode='train')\n",
        "valid_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# Test\n",
        "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "M5SdJtXs0xpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score_function(real, pred):\n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "def precision_score_function(real, pred):\n",
        "  precision = precision_score(real, pred, average='macro')\n",
        "  return precision\n",
        "\n",
        "def recall_score_function(real, pred):\n",
        "  recall = recall_score(real, pred, average='macro')\n",
        "  return recall\n",
        "\n",
        "model = Network().to(device)\n",
        "\n",
        "WEIGHT_DECAY = 1e-2\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.999), weight_decay=WEIGHT_DECAY)\n",
        "criterion = nn.CrossEntropyLoss(weight=weight_list_all_tensor)\n",
        "scaler = torch.cuda.amp.GradScaler() "
      ],
      "metadata": {
        "id": "WFKj-YF50xng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best=0\n",
        "best_f1 = 0\n",
        "for epoch in range(epochs):\n",
        "    start=time.time()\n",
        "    train_loss = 0\n",
        "    train_pred=[]\n",
        "    train_y=[]\n",
        "    model.train()\n",
        "    for batch in (train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        loss = criterion(pred.float(), y)\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item()/len(train_loader)\n",
        "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "        train_y += y.detach().cpu().numpy().tolist()\n",
        "    \n",
        "    # train_precision = precision_score_function(train_y, train_pred)\n",
        "    # train_recall = recall_score_function(train_y, train_pred)\n",
        "    # train_f1 = f1_score_function(train_y, train_pred)\n",
        "\n",
        "    # if train_f1 > best_f1:\n",
        "    #   best_f1 = train_f1\n",
        "    #   best_f1_model = deepcopy(model.state_dict())\n",
        "\n",
        "    valid_pred = []\n",
        "    valid_y = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in (valid_loader):\n",
        "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        valid_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "        valid_y += y.detach().cpu().numpy().tolist()\n",
        "\n",
        "    valid_precision = precision_score_function(valid_y, valid_pred)\n",
        "    valid_recall = recall_score_function(valid_y, valid_pred)\n",
        "    valid_f1 = f1_score_function(valid_y, valid_pred)\n",
        "\n",
        "    torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/data/bestmodel_state_dict.pt\")\n",
        "\n",
        "    TIME = time.time() - start\n",
        "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
        "    print(f'VALID    loss : {train_loss:.5f}   precision : {valid_precision:.5f}     recall : {valid_recall:.5f}    f1 : {valid_f1:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITwym4690xkM",
        "outputId": "0cb0d60b-130f-4d1a-e01e-06e48219d201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1/24    time : 68s/1553s\n",
            "VALID    loss : 1.80026   precision : 0.31926     recall : 0.35260    f1 : 0.29814\n",
            "epoch : 2/24    time : 68s/1485s\n",
            "VALID    loss : 0.98550   precision : 0.55434     recall : 0.53522    f1 : 0.49507\n",
            "epoch : 3/24    time : 68s/1419s\n",
            "VALID    loss : 0.77617   precision : 0.62757     recall : 0.62602    f1 : 0.58982\n",
            "epoch : 4/24    time : 68s/1359s\n",
            "VALID    loss : 0.63626   precision : 0.69906     recall : 0.63485    f1 : 0.62065\n",
            "epoch : 5/24    time : 68s/1301s\n",
            "VALID    loss : 0.50559   precision : 0.72869     recall : 0.69860    f1 : 0.67800\n",
            "epoch : 6/24    time : 68s/1232s\n",
            "VALID    loss : 0.45117   precision : 0.81884     recall : 0.80870    f1 : 0.76692\n",
            "epoch : 7/24    time : 69s/1165s\n",
            "VALID    loss : 0.40406   precision : 0.85021     recall : 0.82425    f1 : 0.80000\n",
            "epoch : 8/24    time : 69s/1097s\n",
            "VALID    loss : 0.31698   precision : 0.88279     recall : 0.86301    f1 : 0.84658\n",
            "epoch : 9/24    time : 69s/1031s\n",
            "VALID    loss : 0.27985   precision : 0.88397     recall : 0.83591    f1 : 0.83293\n",
            "epoch : 10/24    time : 69s/963s\n",
            "VALID    loss : 0.26263   precision : 0.89323     recall : 0.87155    f1 : 0.86081\n",
            "epoch : 11/24    time : 69s/893s\n",
            "VALID    loss : 0.23072   precision : 0.84616     recall : 0.85435    f1 : 0.83486\n",
            "epoch : 12/24    time : 69s/826s\n",
            "VALID    loss : 0.24485   precision : 0.89278     recall : 0.87940    f1 : 0.85887\n",
            "epoch : 13/24    time : 69s/757s\n",
            "VALID    loss : 0.18548   precision : 0.92243     recall : 0.91782    f1 : 0.90674\n",
            "epoch : 14/24    time : 69s/688s\n",
            "VALID    loss : 0.15486   precision : 0.89408     recall : 0.91093    f1 : 0.87780\n",
            "epoch : 15/24    time : 69s/618s\n",
            "VALID    loss : 0.12493   precision : 0.90494     recall : 0.91181    f1 : 0.88953\n",
            "epoch : 16/24    time : 69s/549s\n",
            "VALID    loss : 0.12296   precision : 0.95621     recall : 0.96622    f1 : 0.95227\n",
            "epoch : 17/24    time : 69s/480s\n",
            "VALID    loss : 0.11166   precision : 0.96945     recall : 0.94025    f1 : 0.94332\n",
            "epoch : 18/24    time : 69s/411s\n",
            "VALID    loss : 0.12747   precision : 0.88649     recall : 0.88307    f1 : 0.86076\n",
            "epoch : 19/24    time : 69s/343s\n",
            "VALID    loss : 0.16713   precision : 0.96897     recall : 0.95469    f1 : 0.95412\n",
            "epoch : 20/24    time : 69s/275s\n",
            "VALID    loss : 0.13378   precision : 0.90410     recall : 0.90540    f1 : 0.88349\n",
            "epoch : 21/24    time : 69s/206s\n",
            "VALID    loss : 0.15406   precision : 0.96029     recall : 0.95117    f1 : 0.94758\n",
            "epoch : 22/24    time : 69s/137s\n",
            "VALID    loss : 0.14377   precision : 0.97847     recall : 0.97062    f1 : 0.96520\n",
            "epoch : 23/24    time : 69s/69s\n",
            "VALID    loss : 0.08660   precision : 0.96972     recall : 0.97085    f1 : 0.96494\n",
            "epoch : 24/24    time : 69s/0s\n",
            "VALID    loss : 0.05073   precision : 0.97458     recall : 0.97076    f1 : 0.96994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/data/bestmodel_state_dict.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnmmgfmAUf81",
        "outputId": "452b68b3-a848-45ca-e439-bdfc4f983427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "a6jvcPis0xgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_decoder = {val:key for key, val in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "H-jCZkDQ0xd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/sample_submission.csv\")\n",
        "submission[\"label\"] = f_result\n",
        "submission\n",
        "submission.to_csv(\"/content/drive/MyDrive/Colab Notebooks/data/Cost function based approach_v5.csv\", index = False)"
      ],
      "metadata": {
        "id": "hk2B-UrM0xba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
