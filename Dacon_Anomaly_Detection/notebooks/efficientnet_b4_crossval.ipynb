{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcmin1018/CV/blob/main/Dacon_Anomaly_Detection/notebooks/efficientnet_b4_crossval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R4RhbmQ4aO95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac207c1f-83ff-4bd4-bce6-35092fdf8fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDkc5JRUVhnr"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/DATA/d/open.zip\" \"/content/data/open.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H67X3RhQXXT"
      },
      "outputs": [],
      "source": [
        "# # !unzip -qq \"zip 파일 경로(.zip)\" -d \"압축 푼 파일 저장할 경로\"\n",
        "!unzip -qq \"/content/data/open.zip\" -d \"/content/data/\"\n",
        "!unzip -qq \"/content/data/open/test.zip\" -d \"/content/data/open/\"\n",
        "!unzip -qq \"/content/data/open/train.zip\" -d \"/content/data/open/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_dK7sxae8Gh",
        "outputId": "acc9578b-759a-4f0f-95e3-ea9a0753bbf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W-7JFTXAPgpa"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import timm\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMiyWJPZgQ8w"
      },
      "outputs": [],
      "source": [
        "path = '/content/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQLL1DUYoXUd"
      },
      "outputs": [],
      "source": [
        "train_png = sorted(glob(path + 'open/train/*.png'))\n",
        "test_png = sorted(glob(path + 'open/test/*.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mCQ3aFNgRE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9017aaf-4e29-46f4-b986-503e715499cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4277, 2154)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(train_png), len(test_png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = pd.read_csv(path +\"open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"]\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]"
      ],
      "metadata": {
        "id": "GrzIUZYUdeDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = train_y['label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "_oCEcpjvquER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_ratio = 10 - normalize *100"
      ],
      "metadata": {
        "id": "tXQwd4zfquy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_list_all = np.ones(88)\n",
        "for key in weight_ratio.index:\n",
        "  idx = label_unique[key]\n",
        "  weight = weight_ratio[key]\n",
        "  weight_list_all[idx] = weight\n",
        "weight_list_all_tensor = torch.FloatTensor(weight_list_all).cuda()\n",
        "print(weight_list_all_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXil2blgq_5_",
        "outputId": "0ac71a8b-2f92-4d1d-ec3b-95695653a3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.7662, 9.7428, 9.7428, 5.1134, 9.8363, 9.8597, 9.8597, 9.8363, 9.8831,\n",
            "        4.7627, 9.8597, 9.8831, 9.8831, 9.7194, 9.7428, 4.8796, 9.7428, 9.7194,\n",
            "        9.7662, 9.7662, 9.7896, 3.4534, 9.7896, 9.7896, 9.7662, 9.8597, 9.8597,\n",
            "        9.8597, 3.8274, 9.8597, 9.8597, 9.7896, 9.7896, 0.8581, 9.7896, 9.7896,\n",
            "        9.7662, 9.7662, 9.7896, 9.7662, 4.2717, 9.7896, 9.6960, 9.7428, 9.7194,\n",
            "        4.8562, 9.7194, 9.6960, 9.7896, 9.7428, 9.6960, 9.7662, 3.7573, 9.8831,\n",
            "        9.7194, 2.5181, 9.7194, 9.7194, 9.6960, 9.7194, 9.7194, 9.7896, 9.7896,\n",
            "        4.6224, 9.8130, 9.7896, 9.8130, 9.6493, 8.5971, 9.8831, 9.8831, 9.8831,\n",
            "        5.0199, 9.8831, 9.9065, 9.8597, 4.2249, 9.8831, 9.8831, 9.7428, 9.7662,\n",
            "        9.8130, 9.7896, 9.8130, 4.3886, 9.7896, 9.7896, 9.8130],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1]\n",
        "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
        "    return img"
      ],
      "metadata": {
        "id": "TTuD4pgideF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SevWlv0MdeIN",
        "outputId": "98f2054d-ec47-4adb-8597-fc52a3bdf104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [02:27<00:00, 28.94it/s]\n",
            "100%|██████████| 2154/2154 [01:11<00:00, 30.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
        "np.save(path + 'test_imgs_384', np.array(test_imgs))"
      ],
      "metadata": {
        "id": "rL7l6nvWdpSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
        "test_imgs = np.load(path + 'test_imgs_384.npy')"
      ],
      "metadata": {
        "id": "LgM6NS3EdeKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
        "# stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
        "\n",
        "# meanR = np.mean([m[0] for m in meanRGB])/255\n",
        "# meanG = np.mean([m[1] for m in meanRGB])/255\n",
        "# meanB = np.mean([m[2] for m in meanRGB])/255\n",
        "\n",
        "# stdR = np.mean([s[0] for s in stdRGB])/255\n",
        "# stdG = np.mean([s[1] for s in stdRGB])/255\n",
        "# stdB = np.mean([s[2] for s in stdRGB])/255\n",
        "\n",
        "# print(\"train 평균\",meanR, meanG, meanB)\n",
        "# print(\"train 표준편차\",stdR, stdG, stdB)"
      ],
      "metadata": {
        "id": "2UNWVsQkdeMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
        "# stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
        "\n",
        "# meanR = np.mean([m[0] for m in meanRGB])/255\n",
        "# meanG = np.mean([m[1] for m in meanRGB])/255\n",
        "# meanB = np.mean([m[2] for m in meanRGB])/255\n",
        "\n",
        "# stdR = np.mean([s[0] for s in stdRGB])/255\n",
        "# stdG = np.mean([s[1] for s in stdRGB])/255\n",
        "# stdB = np.mean([s[2] for s in stdRGB])/255\n",
        "\n",
        "# print(\"test 평균\",meanR, meanG, meanB)\n",
        "# print(\"test 표준편차\",stdR, stdG, stdB)"
      ],
      "metadata": {
        "id": "amlMxWo9deOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_dataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode == 'train':\n",
        "          train_transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
        "                                     std = [0.181572, 0.174035, 0.163234]),\n",
        "                transforms.RandomAffine((-45, 45)),\n",
        "                \n",
        "            ])\n",
        "          img = train_transform(img)\n",
        "        if self.mode == 'test':\n",
        "          test_transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
        "                                     std = [0.195055, 0.190053, 0.185323])\n",
        "            ])\n",
        "          img = test_transform(img)\n",
        "\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "    \n",
        "class Network(nn.Module):\n",
        "    def __init__(self,mode = 'train'):\n",
        "        super(Network, self).__init__()\n",
        "        self.mode = mode\n",
        "        if self.mode == 'train':\n",
        "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n",
        "        if self.mode == 'test':\n",
        "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Tb7GNLmQdeQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_function(real, pred):\n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score"
      ],
      "metadata": {
        "id": "RtZUoFS5dya-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(seed = 20):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "main(20)"
      ],
      "metadata": {
        "id": "K5C3CVzbdydD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "cv = StratifiedKFold(n_splits = 5, random_state = 20,shuffle=True)\n",
        "batch_size = 16\n",
        "epochs = 70\n",
        "pred_ensemble = []\n",
        "\n",
        "\n",
        "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
        "  print(\"----------fold_{} start!----------\".format(idx))\n",
        "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
        "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
        "\n",
        "  # Train\n",
        "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
        "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "  # Val\n",
        "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
        "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  best=0\n",
        "\n",
        "  model = Network().to(device)\n",
        "\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
        "  criterion = nn.CrossEntropyLoss(weight=weight_list_all_tensor)\n",
        "  scaler = torch.cuda.amp.GradScaler()  \n",
        "\n",
        "  best_f1 = 0\n",
        "  early_stopping = 0\n",
        "  for epoch in range(epochs):\n",
        "    start=time.time()\n",
        "    train_loss = 0\n",
        "    train_pred=[]\n",
        "    train_y=[]\n",
        "    model.train()\n",
        "    for batch in (train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        loss = criterion(pred.float(), y)\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item()/len(train_loader)\n",
        "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "        train_y += y.detach().cpu().numpy().tolist()\n",
        "\n",
        "        \n",
        "    train_f1 = score_function(train_y, train_pred)\n",
        "    state_dict= model.state_dict()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss = 0 \n",
        "      val_pred = []\n",
        "      val_y = []\n",
        "      \n",
        "\n",
        "      for batch in (val_loader):\n",
        "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred_val = model(x_val)\n",
        "        loss_val = criterion(pred_val.float(), y_val)\n",
        "\n",
        "        val_loss += loss_val.item()/len(val_loader)\n",
        "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
        "        val_y += y_val.detach().cpu().numpy().tolist()\n",
        "        \n",
        "      val_f1 = score_function(val_y, val_pred)\n",
        "\n",
        "      if val_f1 > best_f1:\n",
        "        best_epoch = epoch\n",
        "        best_loss = val_loss\n",
        "        best_f1 = val_f1\n",
        "        early_stopping = 0\n",
        "\n",
        "        torch.save({'epoch':epoch,\n",
        "                    'state_dict':state_dict,\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                    'scaler': scaler.state_dict(),\n",
        "             }, path +'best_model_{}.pth'.format(idx))\n",
        "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
        "      else:\n",
        "          early_stopping += 1\n",
        "\n",
        "            # Early Stopping\n",
        "      if early_stopping == 15:\n",
        "        TIME = time.time() - start\n",
        "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
        "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
        "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
        "        break\n",
        "\n",
        "    TIME = time.time() - start\n",
        "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
        "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
        "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
      ],
      "metadata": {
        "id": "8TIBIh8KdyfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95697b0e-7e2b-4cbf-8a05-0acb9b535545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------fold_0 start!----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------SAVE:1 epoch----------------\n",
            "epoch : 1/70    time : 124s/8584s\n",
            "TRAIN    loss : 2.08980    f1 : 0.16041\n",
            "Val    loss : 1.22532    f1 : 0.25280\n",
            "-----------------SAVE:2 epoch----------------\n",
            "epoch : 2/70    time : 119s/8121s\n",
            "TRAIN    loss : 1.00427    f1 : 0.32177\n",
            "Val    loss : 0.83672    f1 : 0.35196\n",
            "-----------------SAVE:3 epoch----------------\n",
            "epoch : 3/70    time : 120s/8021s\n",
            "TRAIN    loss : 0.73817    f1 : 0.46127\n",
            "Val    loss : 0.64294    f1 : 0.46393\n",
            "-----------------SAVE:4 epoch----------------\n",
            "epoch : 4/70    time : 120s/7892s\n",
            "TRAIN    loss : 0.59753    f1 : 0.55864\n",
            "Val    loss : 0.59597    f1 : 0.55023\n",
            "-----------------SAVE:5 epoch----------------\n",
            "epoch : 5/70    time : 120s/7771s\n",
            "TRAIN    loss : 0.48266    f1 : 0.64859\n",
            "Val    loss : 0.55017    f1 : 0.59360\n",
            "-----------------SAVE:6 epoch----------------\n",
            "epoch : 6/70    time : 120s/7662s\n",
            "TRAIN    loss : 0.38356    f1 : 0.70414\n",
            "Val    loss : 0.52265    f1 : 0.60249\n",
            "-----------------SAVE:7 epoch----------------\n",
            "epoch : 7/70    time : 120s/7556s\n",
            "TRAIN    loss : 0.31113    f1 : 0.76652\n",
            "Val    loss : 0.46509    f1 : 0.62969\n",
            "-----------------SAVE:8 epoch----------------\n",
            "epoch : 8/70    time : 120s/7425s\n",
            "TRAIN    loss : 0.26149    f1 : 0.82317\n",
            "Val    loss : 0.38986    f1 : 0.71846\n",
            "epoch : 9/70    time : 119s/7266s\n",
            "TRAIN    loss : 0.22741    f1 : 0.83574\n",
            "Val    loss : 0.42126    f1 : 0.71033\n",
            "epoch : 10/70    time : 119s/7142s\n",
            "TRAIN    loss : 0.15728    f1 : 0.88002\n",
            "Val    loss : 0.39448    f1 : 0.71676\n",
            "epoch : 11/70    time : 119s/7011s\n",
            "TRAIN    loss : 0.14100    f1 : 0.91194\n",
            "Val    loss : 0.41150    f1 : 0.70642\n",
            "-----------------SAVE:12 epoch----------------\n",
            "epoch : 12/70    time : 120s/6944s\n",
            "TRAIN    loss : 0.13208    f1 : 0.90477\n",
            "Val    loss : 0.43664    f1 : 0.74875\n",
            "epoch : 13/70    time : 120s/6818s\n",
            "TRAIN    loss : 0.12907    f1 : 0.91597\n",
            "Val    loss : 0.37625    f1 : 0.73132\n",
            "-----------------SAVE:14 epoch----------------\n",
            "epoch : 14/70    time : 120s/6710s\n",
            "TRAIN    loss : 0.09342    f1 : 0.93421\n",
            "Val    loss : 0.40081    f1 : 0.77318\n",
            "epoch : 15/70    time : 119s/6544s\n",
            "TRAIN    loss : 0.09187    f1 : 0.93494\n",
            "Val    loss : 0.39348    f1 : 0.73800\n",
            "epoch : 16/70    time : 118s/6394s\n",
            "TRAIN    loss : 0.08366    f1 : 0.94148\n",
            "Val    loss : 0.36684    f1 : 0.76053\n",
            "epoch : 17/70    time : 119s/6293s\n",
            "TRAIN    loss : 0.06074    f1 : 0.95836\n",
            "Val    loss : 0.52302    f1 : 0.76223\n",
            "epoch : 18/70    time : 119s/6165s\n",
            "TRAIN    loss : 0.05650    f1 : 0.96022\n",
            "Val    loss : 0.41705    f1 : 0.76560\n",
            "epoch : 19/70    time : 118s/6020s\n",
            "TRAIN    loss : 0.07566    f1 : 0.93694\n",
            "Val    loss : 0.43535    f1 : 0.76710\n",
            "epoch : 20/70    time : 118s/5901s\n",
            "TRAIN    loss : 0.06759    f1 : 0.94873\n",
            "Val    loss : 0.49241    f1 : 0.76335\n",
            "epoch : 21/70    time : 118s/5772s\n",
            "TRAIN    loss : 0.07116    f1 : 0.95192\n",
            "Val    loss : 0.37378    f1 : 0.74707\n",
            "epoch : 22/70    time : 118s/5665s\n",
            "TRAIN    loss : 0.05639    f1 : 0.97228\n",
            "Val    loss : 0.49042    f1 : 0.75866\n",
            "epoch : 23/70    time : 118s/5537s\n",
            "TRAIN    loss : 0.05660    f1 : 0.96819\n",
            "Val    loss : 0.44693    f1 : 0.77221\n",
            "-----------------SAVE:24 epoch----------------\n",
            "epoch : 24/70    time : 119s/5455s\n",
            "TRAIN    loss : 0.03234    f1 : 0.97598\n",
            "Val    loss : 0.38787    f1 : 0.77444\n",
            "-----------------SAVE:25 epoch----------------\n",
            "epoch : 25/70    time : 119s/5344s\n",
            "TRAIN    loss : 0.07033    f1 : 0.96473\n",
            "Val    loss : 0.42884    f1 : 0.77852\n",
            "epoch : 26/70    time : 118s/5193s\n",
            "TRAIN    loss : 0.04327    f1 : 0.97707\n",
            "Val    loss : 0.38694    f1 : 0.76471\n",
            "epoch : 27/70    time : 118s/5085s\n",
            "TRAIN    loss : 0.03542    f1 : 0.97376\n",
            "Val    loss : 0.44248    f1 : 0.77116\n",
            "epoch : 28/70    time : 118s/4952s\n",
            "TRAIN    loss : 0.03931    f1 : 0.97760\n",
            "Val    loss : 0.48848    f1 : 0.75038\n",
            "-----------------SAVE:29 epoch----------------\n",
            "epoch : 29/70    time : 118s/4852s\n",
            "TRAIN    loss : 0.02733    f1 : 0.97181\n",
            "Val    loss : 0.38199    f1 : 0.80245\n",
            "epoch : 30/70    time : 118s/4716s\n",
            "TRAIN    loss : 0.05653    f1 : 0.96398\n",
            "Val    loss : 0.48861    f1 : 0.79293\n",
            "epoch : 31/70    time : 118s/4598s\n",
            "TRAIN    loss : 0.03669    f1 : 0.95494\n",
            "Val    loss : 0.38523    f1 : 0.78973\n",
            "epoch : 32/70    time : 118s/4477s\n",
            "TRAIN    loss : 0.02189    f1 : 0.98736\n",
            "Val    loss : 0.52501    f1 : 0.76698\n",
            "epoch : 33/70    time : 118s/4364s\n",
            "TRAIN    loss : 0.03946    f1 : 0.97743\n",
            "Val    loss : 0.43634    f1 : 0.75897\n",
            "epoch : 34/70    time : 118s/4244s\n",
            "TRAIN    loss : 0.02156    f1 : 0.98691\n",
            "Val    loss : 0.45914    f1 : 0.76964\n",
            "epoch : 35/70    time : 118s/4118s\n",
            "TRAIN    loss : 0.03438    f1 : 0.97947\n",
            "Val    loss : 0.48574    f1 : 0.75086\n",
            "epoch : 36/70    time : 117s/3994s\n",
            "TRAIN    loss : 0.03033    f1 : 0.98221\n",
            "Val    loss : 0.50733    f1 : 0.76494\n",
            "epoch : 37/70    time : 118s/3878s\n",
            "TRAIN    loss : 0.01693    f1 : 0.98308\n",
            "Val    loss : 0.52529    f1 : 0.75420\n",
            "epoch : 38/70    time : 118s/3762s\n",
            "TRAIN    loss : 0.02761    f1 : 0.97918\n",
            "Val    loss : 0.51817    f1 : 0.74953\n",
            "epoch : 39/70    time : 118s/3645s\n",
            "TRAIN    loss : 0.05714    f1 : 0.96349\n",
            "Val    loss : 0.40004    f1 : 0.75481\n",
            "epoch : 40/70    time : 117s/3519s\n",
            "TRAIN    loss : 0.02445    f1 : 0.98077\n",
            "Val    loss : 0.48354    f1 : 0.77807\n",
            "epoch : 41/70    time : 117s/3405s\n",
            "TRAIN    loss : 0.03303    f1 : 0.97458\n",
            "Val    loss : 0.52487    f1 : 0.75243\n",
            "epoch : 42/70    time : 118s/3293s\n",
            "TRAIN    loss : 0.03127    f1 : 0.98293\n",
            "Val    loss : 0.53225    f1 : 0.76291\n",
            "epoch : 43/70    time : 117s/3171s\n",
            "TRAIN    loss : 0.02268    f1 : 0.99303\n",
            "Val    loss : 0.48053    f1 : 0.76377\n",
            "epoch : 44/70    time : 118s/3057s\n",
            "TRAIN    loss : 0.02474    f1 : 0.98709\n",
            "Val    loss : 0.54449    f1 : 0.76346\n",
            "----------fold_1 start!----------\n",
            "-----------------SAVE:1 epoch----------------\n",
            "epoch : 1/70    time : 119s/8201s\n",
            "TRAIN    loss : 2.07558    f1 : 0.15907\n",
            "Val    loss : 1.12043    f1 : 0.23442\n",
            "-----------------SAVE:2 epoch----------------\n",
            "epoch : 2/70    time : 119s/8101s\n",
            "TRAIN    loss : 1.07674    f1 : 0.28568\n",
            "Val    loss : 0.79654    f1 : 0.36933\n",
            "-----------------SAVE:3 epoch----------------\n",
            "epoch : 3/70    time : 119s/7970s\n",
            "TRAIN    loss : 0.79141    f1 : 0.42062\n",
            "Val    loss : 0.66052    f1 : 0.47743\n",
            "-----------------SAVE:4 epoch----------------\n",
            "epoch : 4/70    time : 119s/7840s\n",
            "TRAIN    loss : 0.62826    f1 : 0.53041\n",
            "Val    loss : 0.54887    f1 : 0.54735\n",
            "-----------------SAVE:5 epoch----------------\n",
            "epoch : 5/70    time : 119s/7724s\n",
            "TRAIN    loss : 0.47103    f1 : 0.63236\n",
            "Val    loss : 0.48060    f1 : 0.61670\n",
            "-----------------SAVE:6 epoch----------------\n",
            "epoch : 6/70    time : 119s/7593s\n",
            "TRAIN    loss : 0.42219    f1 : 0.69231\n",
            "Val    loss : 0.42713    f1 : 0.65047\n",
            "-----------------SAVE:7 epoch----------------\n",
            "epoch : 7/70    time : 119s/7484s\n",
            "TRAIN    loss : 0.32666    f1 : 0.76127\n",
            "Val    loss : 0.40662    f1 : 0.67723\n",
            "-----------------SAVE:8 epoch----------------\n",
            "epoch : 8/70    time : 119s/7371s\n",
            "TRAIN    loss : 0.26560    f1 : 0.79748\n",
            "Val    loss : 0.39525    f1 : 0.73044\n",
            "-----------------SAVE:9 epoch----------------\n",
            "epoch : 9/70    time : 119s/7284s\n",
            "TRAIN    loss : 0.20690    f1 : 0.85257\n",
            "Val    loss : 0.36308    f1 : 0.75225\n",
            "epoch : 10/70    time : 118s/7090s\n",
            "TRAIN    loss : 0.16153    f1 : 0.86887\n",
            "Val    loss : 0.31522    f1 : 0.74211\n",
            "epoch : 11/70    time : 118s/6965s\n",
            "TRAIN    loss : 0.15872    f1 : 0.87928\n",
            "Val    loss : 0.29403    f1 : 0.74986\n",
            "-----------------SAVE:12 epoch----------------\n",
            "epoch : 12/70    time : 119s/6876s\n",
            "TRAIN    loss : 0.15203    f1 : 0.91143\n",
            "Val    loss : 0.28454    f1 : 0.78014\n",
            "epoch : 13/70    time : 118s/6727s\n",
            "TRAIN    loss : 0.12081    f1 : 0.91608\n",
            "Val    loss : 0.27009    f1 : 0.77475\n",
            "-----------------SAVE:14 epoch----------------\n",
            "epoch : 14/70    time : 119s/6643s\n",
            "TRAIN    loss : 0.10224    f1 : 0.92784\n",
            "Val    loss : 0.29470    f1 : 0.78694\n",
            "epoch : 15/70    time : 118s/6487s\n",
            "TRAIN    loss : 0.08614    f1 : 0.93321\n",
            "Val    loss : 0.29360    f1 : 0.78277\n",
            "-----------------SAVE:16 epoch----------------\n",
            "epoch : 16/70    time : 119s/6410s\n",
            "TRAIN    loss : 0.08461    f1 : 0.95249\n",
            "Val    loss : 0.31235    f1 : 0.79938\n",
            "epoch : 17/70    time : 118s/6254s\n",
            "TRAIN    loss : 0.10270    f1 : 0.92840\n",
            "Val    loss : 0.33155    f1 : 0.76755\n",
            "epoch : 18/70    time : 118s/6130s\n",
            "TRAIN    loss : 0.07701    f1 : 0.93979\n",
            "Val    loss : 0.31238    f1 : 0.79930\n",
            "-----------------SAVE:19 epoch----------------\n",
            "epoch : 19/70    time : 119s/6059s\n",
            "TRAIN    loss : 0.04838    f1 : 0.96285\n",
            "Val    loss : 0.35890    f1 : 0.79959\n",
            "-----------------SAVE:20 epoch----------------\n",
            "epoch : 20/70    time : 119s/5945s\n",
            "TRAIN    loss : 0.07151    f1 : 0.95234\n",
            "Val    loss : 0.32526    f1 : 0.80126\n",
            "epoch : 21/70    time : 118s/5801s\n",
            "TRAIN    loss : 0.07068    f1 : 0.95320\n",
            "Val    loss : 0.30461    f1 : 0.79817\n",
            "-----------------SAVE:22 epoch----------------\n",
            "epoch : 22/70    time : 119s/5703s\n",
            "TRAIN    loss : 0.05451    f1 : 0.95646\n",
            "Val    loss : 0.35202    f1 : 0.84640\n",
            "epoch : 23/70    time : 118s/5536s\n",
            "TRAIN    loss : 0.06211    f1 : 0.95333\n",
            "Val    loss : 0.25753    f1 : 0.84360\n",
            "epoch : 24/70    time : 118s/5423s\n",
            "TRAIN    loss : 0.05586    f1 : 0.96959\n",
            "Val    loss : 0.31266    f1 : 0.80608\n",
            "epoch : 25/70    time : 118s/5302s\n",
            "TRAIN    loss : 0.04280    f1 : 0.97468\n",
            "Val    loss : 0.25977    f1 : 0.82536\n",
            "epoch : 26/70    time : 118s/5189s\n",
            "TRAIN    loss : 0.02936    f1 : 0.97422\n",
            "Val    loss : 0.28503    f1 : 0.80863\n",
            "epoch : 27/70    time : 118s/5071s\n",
            "TRAIN    loss : 0.04416    f1 : 0.97332\n",
            "Val    loss : 0.25887    f1 : 0.82596\n",
            "epoch : 28/70    time : 118s/4951s\n",
            "TRAIN    loss : 0.02828    f1 : 0.98076\n",
            "Val    loss : 0.30140    f1 : 0.81261\n",
            "epoch : 29/70    time : 118s/4826s\n",
            "TRAIN    loss : 0.03752    f1 : 0.98503\n",
            "Val    loss : 0.24821    f1 : 0.80749\n",
            "epoch : 30/70    time : 118s/4716s\n",
            "TRAIN    loss : 0.02560    f1 : 0.98644\n",
            "Val    loss : 0.29611    f1 : 0.79130\n",
            "epoch : 31/70    time : 118s/4600s\n",
            "TRAIN    loss : 0.02232    f1 : 0.98593\n",
            "Val    loss : 0.31142    f1 : 0.81446\n",
            "epoch : 32/70    time : 118s/4486s\n",
            "TRAIN    loss : 0.02754    f1 : 0.98592\n",
            "Val    loss : 0.30817    f1 : 0.82097\n",
            "epoch : 33/70    time : 119s/4398s\n",
            "TRAIN    loss : 0.03370    f1 : 0.98337\n",
            "Val    loss : 0.31347    f1 : 0.80891\n",
            "epoch : 34/70    time : 119s/4292s\n",
            "TRAIN    loss : 0.03518    f1 : 0.97469\n",
            "Val    loss : 0.28651    f1 : 0.83446\n",
            "epoch : 35/70    time : 119s/4171s\n",
            "TRAIN    loss : 0.02775    f1 : 0.97172\n",
            "Val    loss : 0.32066    f1 : 0.83562\n",
            "epoch : 36/70    time : 119s/4047s\n",
            "TRAIN    loss : 0.04382    f1 : 0.96624\n",
            "Val    loss : 0.34581    f1 : 0.83070\n",
            "epoch : 37/70    time : 119s/3929s\n",
            "TRAIN    loss : 0.02670    f1 : 0.98079\n",
            "Val    loss : 0.36058    f1 : 0.83575\n",
            "----------fold_2 start!----------\n",
            "-----------------SAVE:1 epoch----------------\n",
            "epoch : 1/70    time : 121s/8376s\n",
            "TRAIN    loss : 2.11787    f1 : 0.17202\n",
            "Val    loss : 1.18971    f1 : 0.23844\n",
            "-----------------SAVE:2 epoch----------------\n",
            "epoch : 2/70    time : 120s/8165s\n",
            "TRAIN    loss : 1.04516    f1 : 0.29364\n",
            "Val    loss : 0.84518    f1 : 0.34394\n",
            "-----------------SAVE:3 epoch----------------\n",
            "epoch : 3/70    time : 120s/8047s\n",
            "TRAIN    loss : 0.77178    f1 : 0.43745\n",
            "Val    loss : 0.65673    f1 : 0.43712\n",
            "-----------------SAVE:4 epoch----------------\n",
            "epoch : 4/70    time : 120s/7941s\n",
            "TRAIN    loss : 0.62734    f1 : 0.52133\n",
            "Val    loss : 0.51528    f1 : 0.56161\n",
            "-----------------SAVE:5 epoch----------------\n",
            "epoch : 5/70    time : 120s/7820s\n",
            "TRAIN    loss : 0.48088    f1 : 0.63999\n",
            "Val    loss : 0.45752    f1 : 0.62823\n",
            "-----------------SAVE:6 epoch----------------\n",
            "epoch : 6/70    time : 120s/7699s\n",
            "TRAIN    loss : 0.38611    f1 : 0.68835\n",
            "Val    loss : 0.38664    f1 : 0.66013\n",
            "-----------------SAVE:7 epoch----------------\n",
            "epoch : 7/70    time : 120s/7589s\n",
            "TRAIN    loss : 0.30509    f1 : 0.78730\n",
            "Val    loss : 0.37633    f1 : 0.70090\n",
            "-----------------SAVE:8 epoch----------------\n",
            "epoch : 8/70    time : 121s/7478s\n",
            "TRAIN    loss : 0.23752    f1 : 0.83638\n",
            "Val    loss : 0.36239    f1 : 0.74236\n",
            "-----------------SAVE:9 epoch----------------\n",
            "epoch : 9/70    time : 121s/7363s\n",
            "TRAIN    loss : 0.20173    f1 : 0.85374\n",
            "Val    loss : 0.38335    f1 : 0.74925\n",
            "-----------------SAVE:10 epoch----------------\n",
            "epoch : 10/70    time : 120s/7224s\n",
            "TRAIN    loss : 0.17527    f1 : 0.88434\n",
            "Val    loss : 0.38575    f1 : 0.75268\n",
            "-----------------SAVE:11 epoch----------------\n",
            "epoch : 11/70    time : 120s/7107s\n",
            "TRAIN    loss : 0.14047    f1 : 0.88312\n",
            "Val    loss : 0.37299    f1 : 0.78007\n",
            "epoch : 12/70    time : 120s/6952s\n",
            "TRAIN    loss : 0.12078    f1 : 0.90337\n",
            "Val    loss : 0.40549    f1 : 0.76490\n",
            "-----------------SAVE:13 epoch----------------\n",
            "epoch : 13/70    time : 120s/6864s\n",
            "TRAIN    loss : 0.11819    f1 : 0.92012\n",
            "Val    loss : 0.37449    f1 : 0.78114\n",
            "epoch : 14/70    time : 120s/6707s\n",
            "TRAIN    loss : 0.12660    f1 : 0.91762\n",
            "Val    loss : 0.36825    f1 : 0.76606\n",
            "-----------------SAVE:15 epoch----------------\n",
            "epoch : 15/70    time : 120s/6617s\n",
            "TRAIN    loss : 0.09185    f1 : 0.93806\n",
            "Val    loss : 0.36402    f1 : 0.79225\n",
            "-----------------SAVE:16 epoch----------------\n",
            "epoch : 16/70    time : 121s/6507s\n",
            "TRAIN    loss : 0.09595    f1 : 0.93998\n",
            "Val    loss : 0.33598    f1 : 0.82487\n",
            "epoch : 17/70    time : 120s/6354s\n",
            "TRAIN    loss : 0.08009    f1 : 0.94005\n",
            "Val    loss : 0.37451    f1 : 0.78935\n",
            "epoch : 18/70    time : 120s/6243s\n",
            "TRAIN    loss : 0.09138    f1 : 0.93929\n",
            "Val    loss : 0.35882    f1 : 0.80970\n",
            "epoch : 19/70    time : 120s/6123s\n",
            "TRAIN    loss : 0.08119    f1 : 0.94530\n",
            "Val    loss : 0.38354    f1 : 0.79619\n",
            "epoch : 20/70    time : 121s/6029s\n",
            "TRAIN    loss : 0.06917    f1 : 0.95573\n",
            "Val    loss : 0.34052    f1 : 0.80258\n",
            "epoch : 21/70    time : 119s/5845s\n",
            "TRAIN    loss : 0.04034    f1 : 0.97424\n",
            "Val    loss : 0.38592    f1 : 0.81203\n",
            "-----------------SAVE:22 epoch----------------\n",
            "epoch : 22/70    time : 120s/5765s\n",
            "TRAIN    loss : 0.04224    f1 : 0.96417\n",
            "Val    loss : 0.36724    f1 : 0.82492\n",
            "epoch : 23/70    time : 119s/5604s\n",
            "TRAIN    loss : 0.04993    f1 : 0.95623\n",
            "Val    loss : 0.34049    f1 : 0.80458\n",
            "epoch : 24/70    time : 119s/5481s\n",
            "TRAIN    loss : 0.03311    f1 : 0.97240\n",
            "Val    loss : 0.40026    f1 : 0.82232\n",
            "-----------------SAVE:25 epoch----------------\n",
            "epoch : 25/70    time : 119s/5376s\n",
            "TRAIN    loss : 0.04364    f1 : 0.96979\n",
            "Val    loss : 0.39981    f1 : 0.82688\n",
            "-----------------SAVE:26 epoch----------------\n",
            "epoch : 26/70    time : 120s/5279s\n",
            "TRAIN    loss : 0.05341    f1 : 0.97201\n",
            "Val    loss : 0.33598    f1 : 0.83490\n",
            "epoch : 27/70    time : 120s/5174s\n",
            "TRAIN    loss : 0.02867    f1 : 0.98231\n",
            "Val    loss : 0.39345    f1 : 0.82595\n",
            "epoch : 28/70    time : 119s/5009s\n",
            "TRAIN    loss : 0.05020    f1 : 0.96432\n",
            "Val    loss : 0.52230    f1 : 0.82505\n",
            "epoch : 29/70    time : 119s/4892s\n",
            "TRAIN    loss : 0.02556    f1 : 0.98004\n",
            "Val    loss : 0.46466    f1 : 0.79814\n",
            "epoch : 30/70    time : 119s/4766s\n",
            "TRAIN    loss : 0.04757    f1 : 0.96403\n",
            "Val    loss : 0.45133    f1 : 0.79915\n",
            "epoch : 31/70    time : 119s/4642s\n",
            "TRAIN    loss : 0.04291    f1 : 0.97315\n",
            "Val    loss : 0.40239    f1 : 0.79885\n",
            "epoch : 32/70    time : 119s/4526s\n",
            "TRAIN    loss : 0.04483    f1 : 0.96509\n",
            "Val    loss : 0.49565    f1 : 0.78504\n",
            "epoch : 33/70    time : 119s/4407s\n",
            "TRAIN    loss : 0.03528    f1 : 0.97629\n",
            "Val    loss : 0.42930    f1 : 0.81140\n",
            "epoch : 34/70    time : 118s/4257s\n",
            "TRAIN    loss : 0.02094    f1 : 0.98197\n",
            "Val    loss : 0.44870    f1 : 0.81757\n",
            "epoch : 35/70    time : 118s/4127s\n",
            "TRAIN    loss : 0.01608    f1 : 0.98965\n",
            "Val    loss : 0.63027    f1 : 0.81302\n",
            "epoch : 36/70    time : 118s/4008s\n",
            "TRAIN    loss : 0.00761    f1 : 0.99301\n",
            "Val    loss : 0.51529    f1 : 0.81833\n",
            "epoch : 37/70    time : 118s/3906s\n",
            "TRAIN    loss : 0.03501    f1 : 0.97913\n",
            "Val    loss : 0.48408    f1 : 0.80372\n",
            "epoch : 38/70    time : 118s/3791s\n",
            "TRAIN    loss : 0.03107    f1 : 0.98173\n",
            "Val    loss : 0.47545    f1 : 0.81094\n",
            "epoch : 39/70    time : 119s/3674s\n",
            "TRAIN    loss : 0.02924    f1 : 0.98324\n",
            "Val    loss : 0.47647    f1 : 0.81356\n",
            "epoch : 40/70    time : 118s/3554s\n",
            "TRAIN    loss : 0.03747    f1 : 0.98299\n",
            "Val    loss : 0.47832    f1 : 0.78490\n",
            "epoch : 41/70    time : 119s/3443s\n",
            "TRAIN    loss : 0.01343    f1 : 0.99136\n",
            "Val    loss : 0.45110    f1 : 0.82480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ensemble = []\n",
        "batch_size = 32\n",
        "# Test\n",
        "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "for i in range(5):\n",
        "  model_test = Network(mode = 'test').to(device)\n",
        "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
        "  model_test.eval()\n",
        "  pred_prob = []\n",
        "  with torch.no_grad():\n",
        "      for batch in (test_loader):\n",
        "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "          with torch.cuda.amp.autocast():\n",
        "              pred = model_test(x)\n",
        "              pred_prob.extend(pred.detach().cpu().numpy())\n",
        "      pred_ensemble.append(pred_prob)"
      ],
      "metadata": {
        "id": "0eF2JKa0dyg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = (np.array(pred_ensemble[1])+ np.array(pred_ensemble[2])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[0]) )/4\n",
        "f_pred = np.array(pred).argmax(1).tolist()"
      ],
      "metadata": {
        "id": "GJeaaXWNeOVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_decoder = {val:key for key, val in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ],
      "metadata": {
        "id": "F2VUiaGGeOYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
        "\n",
        "submission[\"label\"] = f_result\n",
        "\n",
        "submission"
      ],
      "metadata": {
        "id": "KhRmIHFjdyjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9aef8314-c362-406e-8133-e4c33384a83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index             label\n",
              "0         0   tile-glue_strip\n",
              "1         1         grid-good\n",
              "2         2   transistor-good\n",
              "3         3  tile-gray_stroke\n",
              "4         4         tile-good\n",
              "...     ...               ...\n",
              "2149   2149  tile-gray_stroke\n",
              "2150   2150        screw-good\n",
              "2151   2151         grid-good\n",
              "2152   2152        cable-good\n",
              "2153   2153       zipper-good\n",
              "\n",
              "[2154 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c9c6a83-2778-4aa9-a9e4-9f0e78dd4d63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tile-glue_strip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>transistor-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>tile-gray_stroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tile-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2149</td>\n",
              "      <td>tile-gray_stroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>2150</td>\n",
              "      <td>screw-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>2151</td>\n",
              "      <td>grid-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>2152</td>\n",
              "      <td>cable-good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>2153</td>\n",
              "      <td>zipper-good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2154 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c9c6a83-2778-4aa9-a9e4-9f0e78dd4d63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c9c6a83-2778-4aa9-a9e4-9f0e78dd4d63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c9c6a83-2778-4aa9-a9e4-9f0e78dd4d63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"final_submission_2.csv\", index = False)"
      ],
      "metadata": {
        "id": "23mDfrKRdykr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TJFXjDTdrqG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "efficientnet_b4_crossval.ipynb의 사본",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}